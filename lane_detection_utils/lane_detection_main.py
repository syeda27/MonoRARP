import cv2
import math
import numpy as np

from scanning_region import scan_region
from road_sampling import brightness_sampling
from outlayer_removal_and_average_brightness import outlayer_removal_and_average_brightness_computation
from average_delta_across_marking import average_delta
from determination_of_parallelism_with_previously_tracked_lanes import determination_of_parallelism
from lane_signature_detection import lane_signature_detection
from eliminate_duplicate_road_marks import eliminate_duplicate_road_marks
from merging_all_road_marks import merging_all_road_marks
from filtering import filtering
from long_term_average import long_term_average_of_lanes


####################################################################################################################################################################################################
# LANE DETECTION
#
# The python script below delivers lane detection based on the LSD (line segment detector) algorithm and its application to the detection of white road markings. The main idea is to sample the 
# brightness of the pixels around the borders of the potential white road mark and extract specific charcateristics/features of the pixels arranged around. Based on these features a particular
# signature for a white road mark is detected. Based on the detected white road marks a line representing the lane is determined by finding the line that crosses all the detected white marks on each 
# side (either left or right).
#
# The script is divided into sections which we will describe below:
#
# I) IMAGE READING
# The image is read in grayscle for processing and in color for visualization. We take the bottom portion of the image (subframe) for LSD processing since this is the area 
# of interest to find white markings.
#
# II) LSD ALGORITHM
# We invoke the LSD algorithm to detect all straight line segments detected on the image. We redraw the detected lines in the image to emphasize the edges for subsequent processing.
#
# III) SCANNING OF THE IMAGE AND DETECTION OF ROAD MARK SIGNATURE
# This section is subdivided as follows:
#     a) Scan region and generate line segments
#     We use a rectangular window that moves over the image subframe and we collect all the line segments inside the region for further analysis.
#
#     b) From all the lines collected in a) we find the two lines that are closest to the top of the scanning region. These two lines will be used to find the signature.
# 
#     c) For the two-top lines found in b) we sample 5 pixels around the two lines. We use horizontal lines that cross the two-top lines and along each horizontal line we sample two pixels
#     to the left of the left-line, two pixels to the right of the right-line and we sample one pixel that is in the middle between the two top-lines (the right-line and the left-line). We
#     extract aggregated statistics based on the samples obtained. These statistics provide the ability to determine the existence of the white road mark signature if it exists.
#
# IV) ELIMINATION OF WHITE ROAD MARK DUPLICATES
# Since the scanning region moves by steps it is possible that a white road marking could be captured more than once by two different positions of the scanning region. Here we eliminate duplicate
# detections of the same white road marking.
#
# V) MERGING ALL WHITE ROAD MARKS PREVIOUSLY DETECTED AND GENERATION OF TWO LANES
# Two o more white road markings detected over the left side of the ego-vehicle are used to determine the line that crosses all of them. This line becomes representative of the Lane defined by
# these white road markings. Similarly the same processing is performed over the right side of the ego-vehicle.
#
# VI) FILTERING WHITE ROAD MARKS TO REMOVE FALSE DETECTIONS AND CORRECTION OF THE TWO LANES
# If we compare the Lane that has been generated by white road marks in the current frame with the Lane that has been obatined in previous frames and we observe a significant deviation in terms of angle
# and horizontal separation we deem the Lane as a false detection and we assign as the current Lane the Lane that was detected on the previous image frame.
#
# VII) RECORDING OF CURRENTLY DETECTED LANES
# We keep a record of the two Lanes detected in the current frame so that we can use them for comparison/validation of future detections.
#
# VIII) GENERATION OF LONG TERM AVERAGE OF THE DETECTED LANES
# We generate a long term average of Lanes detected over the last 6 frames in order to provide stability to the detection and dampen transients.
#
# IX) DISPLAY
# We display the image emphasizing the area of the road with the white markings. This causes an aspect ration distortion overall, however the details of the detection are clearly visible.
#
#
####################################################################################################################################################################################################


##################### INITIALIZATION OF VARIABLES ###########################

count_lanes_previous=0
mux_lane_vec_previous=np.zeros(40)
muy_lane_vec_previous=np.zeros(40)
base_ptx_lane_vec_previous=np.zeros(40)
base_pty_lane_vec_previous=np.zeros(40)

count_lanes_previous2=0
mux_lane_vec_previous2=np.zeros(40)
muy_lane_vec_previous2=np.zeros(40)
base_ptx_lane_vec_previous2=np.zeros(40)
base_pty_lane_vec_previous2=np.zeros(40)

count_lanes_aggregated=0
mux_lane_vec_aggregated=np.zeros(40)
muy_lane_vec_aggregated=np.zeros(40)
base_ptx_lane_vec_aggregated=np.zeros(40)
base_pty_lane_vec_aggregated=np.zeros(40)

count_lanes_average_vec=0
mux_lane_vec_average=np.zeros(4000)
muy_lane_vec_average=np.zeros(4000)
base_ptx_lane_vec_average=np.zeros(4000)
base_pty_lane_vec_average=np.zeros(4000)

count_lanes_average_vec2=0
mux_lane_vec_average2=np.zeros(4000)
muy_lane_vec_average2=np.zeros(4000)
base_ptx_lane_vec_average2=np.zeros(4000)
base_pty_lane_vec_average2=np.zeros(4000)

count_lane_group1=0
count_lane_group2=0

white_mark_hit=0
count_road_nomark=0
capture_frameindex_for_speed=0
frameindex_for_speed_previous=0
frameindex_for_speed=0
count_scanned_lines_reverse_for_speed_previous=0
count_scanned_lines_reverse_for_speed=0


white_mark_hit_1=0
count_road_nomark_1=0
capture_frameindex_for_speed_1=0
frameindex_for_speed_previous_1=0
frameindex_for_speed_1=0
count_scanned_lines_reverse_for_speed_previous_1=0
count_scanned_lines_reverse_for_speed_1=0

base_ptx_lane_vec_final1=0
base_pty_lane_vec_final1=0
mux_lane_vec_final1=0
muy_lane_vec_final1=0

base_ptx_lane_vec_final2=0
base_pty_lane_vec_final2=0
mux_lane_vec_final2=0
muy_lane_vec_final2=0

mux_lane_vec_final1_previous=0
muy_lane_vec_final1_previous=0
base_ptx_lane_vec_final1_previous=0
base_pty_lane_vec_final1_previous=0

mux_lane_vec_final2_previous=0
muy_lane_vec_final2_previous=0
base_ptx_lane_vec_final2_previous=0
base_pty_lane_vec_final2_previous=0

x1_lane_group1=0
x1_lane_group2=0


initial_frame_was_processed_flag=0

first_reading_available_flag=0


########### CONFIGURABLE PARAMETERS #################

#inital and end points for the scanning in the x-direction within the image subframe, and step of the scanning
scan_x_ini=1480
scan_x_end=2720
scan_x_step=80

#inital and end points for the scanning in the y-direction within the image subframe, and step of the scanning
scan_y_ini=100
scan_y_end=250
scan_y_step=20

#size of the rectangular window used for the scanning
scanning_window_width=120
scanning_window_lenght=160


########### BEGINNING OF LANE DETECTION ################

for image_number in range(1085,2665):


    ######## IMAGE READING ########
    
    #Reading of Image Frame
    image_name='./Hwy101_frames/'+str(image_number)+'.jpg'               

    img = cv2.imread(image_name,cv2.IMREAD_GRAYSCALE) #image for processing algorithm
    img3 = cv2.imread(image_name)                     #image for visualization of results (in color)
    img2=img[1500:1800,0:3849]			      #image subframe that is closer to the bottom part of the frame where markings are more visible.
    img4 = img3[1500:1800,0:3849]                     #image subframe for visualization of results (in color)
         
    H, W =img.shape
    h1, w1= img2.shape
    
    count_lanes=0
    
    #Initialization on every frame
    mux_lane_vec=np.zeros(40)
    muy_lane_vec=np.zeros(40)
    base_ptx_lane_vec=np.zeros(40)
    base_pty_lane_vec=np.zeros(40)
    angle_lanes=np.zeros(40)
    



    ######## LSD ALGORITHM ########    

    #LSD algorithm object creation
    lsd = cv2.createLineSegmentDetector(0)

    #LSD line segment detection
    dlines = lsd.detect(img2)  #dlines holds the lines that have been detected by LSD
    for dline in dlines[0]:
        x0 = int(round(dline[0][0]))
        y0 = int(round(dline[0][1]))
        x1 = int(round(dline[0][2]))
        y1 = int(round(dline[0][3]))
        cv2.line(img2, (x0, y0), (x1,y1), 255, 1, cv2.LINE_AA)  #we are redrawing the lines to emphasize their borders

    img6 = img4.copy() 

          
    
    ######## SCANNING OF THE IMAGE AND DETECTION OF ROAD MARK SIGNATURE ######## 
       
    for xregion in range(scan_x_ini,scan_x_end,scan_x_step):
        
        for yregion in range(scan_y_ini,scan_y_end,scan_y_step):
  

            # a) Scan region and generate line segments
            rx1,rx2,ry1,ry2,angles,count_angles_per_region = scan_region(dlines,xregion,yregion,scanning_window_lenght,scanning_window_width)
                        
          

            if count_angles_per_region>=2:  #perform all the following processing only if 2 or more line-segments exists per scanning region


                # b) From all the lines we found inside a scaning region we find the two top line-segments (closest to the top of the frame). 
 
                first_top=-1
                second_top=-1

                top=10000
                for k1 in range(0,count_angles_per_region):
                     if ry1[k1]<top:   
                         top=ry1[k1]
                         first_top=k1
                top=10000
                for k1 in range(0,count_angles_per_region):
                     if ry1[k1]<top and k1!=first_top:
                         top=ry1[k1]
                         second_top=k1

                # There will be one top segment on the left and another on the right. Out of the two top segments indetify which segment is to the left and which to the right
                if rx1[first_top]<rx1[second_top]:
                    top_left=first_top   
                    top_right=second_top
                else:
                    top_left=second_top   
                    top_right=first_top
               


                # c) Sampling of 5 pixels around the two top line segments for each horizontal line crossing the two line segments, and detection of signature

                # criteria that must be complied with to proceed to the sampling:
                # 1) the top-left line and the top-right line should be aliged vertically so that horizontal lines would intersect both of them (at least for some portion of both)
                # 2) The difference between the top-left line's angle and the top-right line's angle should be less than 6 degrees
                if ry2[top_left]>ry1[top_right] and ry2[top_right]>ry1[top_left] and abs(angles[top_right]-angles[top_left])<6:

                    # c1) Brightness Sampling in groups of 5 pixels (sample types: 4 samples for pavement and 1 sample for white road mark). One vector per sample type holding samples across vertical dim.
                    road1_vec,road2_vec,road3_vec,road4_vec,whitemarkings_vec,counter_scanning = brightness_sampling(rx1,rx2,ry1,ry2,top_left,top_right,img2)
                
         
                    # c2) Artifact Removal and Computation of Average Brightness across the vertical dimension for each sample type 
                    road1_average,road2_average,road3_average,road4_average,whitemarkings_average,removed3,removed4 = outlayer_removal_and_average_brightness_computation(road1_vec,road2_vec,road3_vec,road4_vec,whitemarkings_vec,counter_scanning)
                    
         
                    # c3) Computation of the Average Delta that exist between each sample and the corresponding average computed across the vertical dimension (this is a meassure of dispersion)
                    delta_road1_average,delta_road2_average,delta_road3_average,delta_road4_average,delta_whitemarkings_average = average_delta(road1_vec,road2_vec,road3_vec,road4_vec,whitemarkings_vec,road1_average,road2_average,road3_average,road4_average,whitemarkings_average,removed3,removed4,counter_scanning)

                    
                    # c4) Verification of alignment of the left top line segment with the lane tracked in the previous frame (important information to be used later)
                    aligned_to_tracked_lane = determination_of_parallelism(top_left,rx1,ry1,count_lane_group1,count_lane_group2,whitemarkings_average,road1_average,base_ptx_lane_vec_final1,base_pty_lane_vec_final1,mux_lane_vec_final1,muy_lane_vec_final1,base_ptx_lane_vec_final2,base_pty_lane_vec_final2,mux_lane_vec_final2,muy_lane_vec_final2,angles)
                    
                                       
                    # c5) Road Mark Signature Detetion for the two-top lines segments previously extracted from the scanning region
                    lane_signature_detected=0

                    lane_signature_detected,mux_lane_vec,muy_lane_vec,base_ptx_lane_vec,base_pty_lane_vec,count_lanes = lane_signature_detection(road1_average,road2_average,road3_average,road4_average,delta_road1_average,delta_road2_average,delta_road3_average,delta_road4_average,whitemarkings_average,delta_whitemarkings_average,rx1,rx2,ry1,ry2,top_left,top_right,mux_lane_vec,muy_lane_vec,base_ptx_lane_vec,base_pty_lane_vec,count_lanes_previous,count_lanes,H,img6)


                    # c6) If Signature Detection fails but the two-top line segments are aligned with a previusly tracked lane we accept the two-top line segments as a white road mark                    
                    if lane_signature_detected==0 and  aligned_to_tracked_lane==1:
   
                        L_lane=((rx1[top_left]-rx2[top_left])**2+(ry1[top_left]-ry2[top_left])**2)**0.5
                        mux_lane=(rx1[top_left]-rx2[top_left])/L_lane
                        muy_lane=(ry1[top_left]-ry2[top_left])/L_lane
                        #intersecting with top of image
                        Lintersection=-ry1[top_left]/muy_lane
                        x1_lane=rx1[top_left]+Lintersection*mux_lane
                        #intersection with bottom of image
                        Lintersection=(H-ry1[top_left])/muy_lane
                        x2_lane=rx1[top_left]+Lintersection*mux_lane
                                        
                                  
                        cv2.line(img6, (int(rx1[top_left]), int(ry1[top_left])), (int(rx2[top_left]),int(ry2[top_left])), (0,0,255), 1, cv2.LINE_AA)
                        cv2.line(img6, (int(rx1[top_right]), int(ry1[top_right])), (int(rx2[top_right]),int(ry2[top_right])), (0,255,0), 1, cv2.LINE_AA)
                            
                        
                        mux_lane_vec[count_lanes]=mux_lane
                        muy_lane_vec[count_lanes]=muy_lane
                        base_ptx_lane_vec[count_lanes]=rx1[top_left]
                        base_pty_lane_vec[count_lanes]=ry1[top_left]
                         
                        count_lanes=count_lanes+1
                        
    
                
    ######## ELIMINATION OF WHITE ROAD MARK DUPLICATES ########

    mux_lane_vec_aggregated,muy_lane_vec_aggregated,base_ptx_lane_vec_aggregated,base_pty_lane_vec_aggregated,angle_lanes,count_tracked_lanes2 = eliminate_duplicate_road_marks(mux_lane_vec,muy_lane_vec,base_ptx_lane_vec,base_pty_lane_vec,count_lanes,mux_lane_vec_aggregated,muy_lane_vec_aggregated,base_ptx_lane_vec_aggregated,base_pty_lane_vec_aggregated,angle_lanes)
            
    
                
    ######## MERGING ALL WHITE ROAD MARKS PREVIOUSLY DETECTED AND GENERATION OF TWO LANES ########
    mux_lane_vec_final1,muy_lane_vec_final1,base_ptx_lane_vec_final1,base_pty_lane_vec_final1,mux_lane_vec_final2,muy_lane_vec_final2,base_ptx_lane_vec_final2,base_pty_lane_vec_final2,count_lane_group1,count_lane_group2 = merging_all_road_marks(angle_lanes,count_tracked_lanes2,mux_lane_vec_aggregated,muy_lane_vec_aggregated,base_ptx_lane_vec_aggregated,base_pty_lane_vec_aggregated)

    
            
    ######## FILTERING WHITE ROAD MARKS TO REMOVE FALSE DETECTIONS AND CORRECTION OF THE TWO LANES #########
    mux_lane_vec_final1,muy_lane_vec_final1,base_ptx_lane_vec_final1,base_pty_lane_vec_final1,mux_lane_vec_final2,muy_lane_vec_final2,base_ptx_lane_vec_final2,base_pty_lane_vec_final2,x1_lane_group1,x1_lane_group2 = filtering(count_lane_group1,count_lane_group2,x1_lane_group1,x1_lane_group2,H,initial_frame_was_processed_flag,mux_lane_vec_final1,muy_lane_vec_final1,base_ptx_lane_vec_final1,base_pty_lane_vec_final1,mux_lane_vec_final1_previous,muy_lane_vec_final1_previous,base_ptx_lane_vec_final1_previous,base_pty_lane_vec_final1_previous,mux_lane_vec_final2,muy_lane_vec_final2,base_ptx_lane_vec_final2,base_pty_lane_vec_final2,mux_lane_vec_final2_previous,muy_lane_vec_final2_previous,base_ptx_lane_vec_final2_previous,base_pty_lane_vec_final2_previous)

     
        
    ######## RECORDING OF CURRENTLY DETECTED LANES ########        
        
    mux_lane_vec_final2_previous=mux_lane_vec_final2
    muy_lane_vec_final2_previous=muy_lane_vec_final2
    base_ptx_lane_vec_final2_previous=base_ptx_lane_vec_final2
    base_pty_lane_vec_final2_previous=base_pty_lane_vec_final2  
    
    mux_lane_vec_final1_previous=mux_lane_vec_final1
    muy_lane_vec_final1_previous=muy_lane_vec_final1
    base_ptx_lane_vec_final1_previous=base_ptx_lane_vec_final1
    base_pty_lane_vec_final1_previous=base_pty_lane_vec_final1  



     ######## GENERATION OF LONG TERM AVERAGE OF THE DETECTED LANES ########
    count_lanes_average_vec,count_lanes_average_vec2,mux_lane_vec_average,muy_lane_vec_average,base_ptx_lane_vec_average,base_pty_lane_vec_average,mux_lane_vec_average2,muy_lane_vec_average2,base_ptx_lane_vec_average2,base_pty_lane_vec_average2 = long_term_average_of_lanes(count_lanes_average_vec,count_lanes_average_vec2,mux_lane_vec_average,muy_lane_vec_average,base_ptx_lane_vec_average,base_pty_lane_vec_average,mux_lane_vec_average2,muy_lane_vec_average2,base_ptx_lane_vec_average2,base_pty_lane_vec_average2,mux_lane_vec_final1,muy_lane_vec_final1,base_ptx_lane_vec_final1,base_pty_lane_vec_final1,mux_lane_vec_final2,muy_lane_vec_final2,base_ptx_lane_vec_final2,base_pty_lane_vec_final2,img6,H)
    
      
    
    initial_frame_was_processed_flag=1

    
    ############## DISPLAY #################

    #resizing image for displaying purposes
    img7=img6
    dim = (3840,2880)    
    resized = cv2.resize(img7, dim, interpolation=cv2.INTER_CUBIC)

    if first_reading_available_flag!=0:
        speed_text='Speed: '+str(int(speed_official))+' miles/hr'
        cv2.putText(resized,speed_text, (250,150), cv2.FONT_HERSHEY_SIMPLEX, 4, (255,255,255),2,cv2.LINE_AA)
    
    cv2.namedWindow('Frame4',cv2.WINDOW_NORMAL)
    cv2.imshow('Frame4',resized )                                               
    cv2.waitKey(1) 
    
   
