# Procedure for the Generation of a Conversion Function
## Objective
The objective of the procedure described below is to obtain a table that provides mapping between
different real-world distances from the camera to the vehicle in front. For this process we will use two
vehicles. One vehicle will have a camera mounted in the dash board (ego-vehicle) and the other vehicle
(leader vehicle) will be used as a reference object that will be visible in front of the ego-vehicle. We
will use a tape measure to measure distances and we will use chalk to draw reference marks on the
pavement. To perform this whole procedure an open area such as a parking lot can be used. The
following steps will be involved in this task.

## Steps
1. Park the ego-vehicle within one of the parking spaces on the parking lot. We should select a
parking space that has no vehicles parked in front so that we have the space available in front of
the ego-vehicle to draw marks and to position the leader vehicle.
2. Use the reference white lines of the parking space that run parallel to the vehicle as initial points
to draw a series of pavement marks. We will draw a series of pavement marks over two
imaginary lines that run as continuation of the white lines mentioned above. The pavement
marks will be drawn with chalk over the pavement and they will be drawn every 5 meters (all
longitudinal distances will be measured from the camera). The idea is to draw the marks so that
when we position the leader vehicle in front of the ego-vehicle we move the leader vehicle
forward while the camera records, the wheels of the leader vehicle will run-over the marks we
drew. We can draw marks up-to an appropriate distance so that the marks are visible on the
recording.
3. We position the leader vehicle in front of the ego-vehicle (as close as possible) and we aim to
have the two vehicles roughly aligned as they would on a highway’s lane (emulating an
scenario where the two vehicles are located on the same lane).
4. We start a recording and we move forward the leader vehicle slowly in front of the ego-vehicle.
As the leader vehicles moves away it should step on the marks we drew one by one every 5
meters. Thus after this whole testing is completed we should have on the recording the image-
frame where the wheels step on the marks which would provide the information on the moment
when the vehicle is at a given distance from camera.
5. Alternatively we can stick a couple of strips of paper to the bumper on the back of vehicle so
that the strips of papers touch the ground slightly. Therefore when the leader vehicle moves
slowly forward we should record the moment when the strip of paper touches the pavement
mark we drew. This should provide a reference on the moment when the actual back of the
leader vehicle is at a given distance from the camera. This is more representative of the data that
we want to capture because the bounding box generated by the neural network provides a
representation of the back of the vehicle (The two back wheels of the vehicle are not exactly on
the back). Another option is that we can also measure the distance between the point where the
back wheels on the leader vehicle touch the ground and the actual back of the vehicle. This way
we only use the wheels as reference and we will always know the distance that the back of the
vehicle is front the camera (by performing subtraction). The only inconvenience is that the
validation function will not be generated using round numbers at 5,10,15,20,...meters butinstead at 5-d,10-d,15-d...meters, where “d” is the distance between the back-wheels and the
back of the vehicle. We can alternatively draw the marks not at 5,10,15,20... meters, but at
5+d,10+d,15+d...meters. We will decide how to proceed.
6. One important step is to measure exactly the width of the leader vehicle so we have this
information for post-processing.
7. We should have a conversion function after the recording.
